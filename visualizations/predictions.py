import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import psycopg2
import os
from dotenv import load_dotenv
from datetime import datetime, timedelta
from visualizations.core import get_db_connection
from sqlalchemy import create_engine, text
from typing import Dict, List, Tuple, Optional, Union
import json

# Load environment variables
load_dotenv()

# Feature descriptions and interpretations
FEATURE_DESCRIPTIONS = {
    'volume': 'Trading volume (number of shares traded)',
    'daily_sentiment': 'Overall sentiment score from news articles',
    'article_count': 'Number of news articles published about the stock',
    'positive_ratio': 'Percentage of positive sentiment in news articles',
    'negative_ratio': 'Percentage of negative sentiment in news articles',
    'neutral_ratio': 'Percentage of neutral sentiment in news articles',
    'real_gdp': 'Real Gross Domestic Product (economic indicator)',
    'unemployment_rate': 'Current unemployment rate percentage',
    'cpi': 'Consumer Price Index (inflation measure)',
    'fed_funds_rate': 'Federal Reserve interest rate',
    'return_1d': 'Previous 1-day price return',
    'return_3d': 'Previous 3-day price return',
    'return_5d': 'Previous 5-day price return',
    'ma7': '7-day moving average price',
    'rsi': 'Relative Strength Index (momentum indicator)',
    'volatility_7d': '7-day price volatility',
    'volume_ma5': '5-day moving average of trading volume',
    'volume_change': 'Daily change in trading volume',
    'sentiment_volume': 'Sentiment weighted by article volume',
    'sentiment_ma3': '3-day moving average of sentiment',
    'high_news_day': 'Flag for days with high news coverage',
    'fed_rate_increase': 'Flag for Federal Reserve rate increase',
    'day_sin': 'Cyclical encoding of day (sine component)',
    'day_cos': 'Cyclical encoding of day (cosine component)',
    'month_end': 'Flag for end of month',
    'inflation_rate': 'Annual percentage change in consumer price index',
    'interest_rate': 'Central bank benchmark interest rate',
    'gdp_growth_rate': 'Quarterly change in gross domestic product',
    'moving_avg_5': '5-day moving average of closing prices',
    'moving_avg_10': '10-day moving average of closing prices',
    'moving_avg_20': '20-day moving average of closing prices',
    'moving_avg_50': '50-day moving average of closing prices',
    'moving_avg_200': '200-day moving average of closing prices',
    'rsi_14': 'Relative Strength Index (14-day) measuring momentum',
    'macd': 'Moving Average Convergence Divergence indicator',
    'bollinger_upper': 'Upper Bollinger Band (20-day, 2 standard deviations)',
    'bollinger_lower': 'Lower Bollinger Band (20-day, 2 standard deviations)',
    'vix': 'Market volatility index representing expected market volatility',
    'atr': 'Average True Range measuring volatility',
    'obv': 'On-Balance Volume indicator relating volume to price change',
    'adx': 'Average Directional Index measuring trend strength',
    'cci': 'Commodity Channel Index measuring cyclical trends',
    'stochastic_k': 'Stochastic Oscillator %K measuring momentum',
    'stochastic_d': 'Stochastic Oscillator %D (3-day SMA of %K)',
    'williams_r': 'Williams %R momentum indicator showing overbought/oversold levels',
    'price_earnings': 'Price to Earnings ratio',
    'market_cap': 'Total market value of a company\'s outstanding shares',
    'dividend_yield': 'Annual dividend payment as percentage of stock price',
    'book_value': 'Company\'s assets minus its liabilities',
    'cash_flow': 'Net amount of cash generated by business operations',
    'revenue_growth': 'Year-over-year percentage change in company revenue',
    'profit_margin': 'Percentage of revenue that exceeds costs'
}

MODEL_INTERPRETATIONS = {
    'random_forest': """
    The Random Forest model calculates feature importance based on how much each feature 
    reduces impurity when used in decision trees. Features with higher importance 
    contribute more to the prediction outcome and represent stronger predictors of 
    price movement.
    """,
    'lightgbm': """
    The LightGBM model calculates feature importance based on the gain achieved when a 
    feature is used for splitting. Features with higher importance contribute more to 
    prediction accuracy and represent the most influential factors in predicting 
    stock price movements.
    """
}

def load_predictions(stock_symbol, start_date=None, end_date=None):
    """
    Load stock price predictions from database
    
    Args:
        stock_symbol: Stock ticker symbol
        start_date: Start date in 'YYYY-MM-DD' format
        end_date: End date in 'YYYY-MM-DD' format
        
    Returns:
        DataFrame with date, stock_symbol, predicted_price, and actual_price columns
    """
    try:
        conn = get_db_connection()
        
        # Adjusted query to use 'prediction' column instead of 'predicted_price'
        query = """
        SELECT p.date, p.stock_symbol, p.prediction as predicted_price, m.close_price as actual_price
        FROM stock_predictions p
        JOIN merged_stocks_new m 
            ON p.date = m.date AND p.stock_symbol = m.stock_symbol
        WHERE p.stock_symbol = %s
         AND p.date >= %s AND p.date <= %s ORDER BY p.date
        """
        
        params = [stock_symbol, start_date, end_date]
        
        # Load predictions
        df = pd.read_sql_query(query, conn, params=params)
        conn.close()
        
        if df.empty:
            print(f"No predictions found for {stock_symbol} between {start_date} and {end_date}")
            return pd.DataFrame()
        
        print(f"Successfully loaded {len(df)} predictions for {stock_symbol}")
        return df
    
    except Exception as e:
        print(f"Error loading prediction data: {e}")
        return pd.DataFrame()

def plot_prediction_comparison(df, stock_symbol, window_size=10):
    """
    Create a comparative visualization of actual vs. predicted prices
    
    Args:
        df: DataFrame with date, predicted_price, and actual_price columns
        stock_symbol: Stock ticker symbol
        window_size: Window size for rolling average
    """
    fig = go.Figure()
    
    # Get the data sorted by date
    df_sorted = df.copy()
    if not pd.api.types.is_datetime64_any_dtype(df_sorted['date']):
        df_sorted['date'] = pd.to_datetime(df_sorted['date'])
    df_sorted = df_sorted.sort_values('date')
    
    # Get all data except the last point for actual price display
    actual_display_df = df_sorted.iloc[:-1].copy()
    
    # Add actual price line (excluding the last point)
    fig.add_trace(
        go.Scatter(
            x=actual_display_df['date'],
            y=actual_display_df['actual_price'],
            mode='lines+markers',
            name='Actual Price',
            line=dict(color='blue', width=2)
        )
    )
    
    # Handle future predictions where actual data might not exist
    # Get the latest date with actual data
    latest_date = df_sorted[df_sorted['actual_price'].notna()]['date'].max()
    
    # Split the data into historical and future predictions
    historical_df = df_sorted[df_sorted['date'] <= latest_date].copy()
    future_df = df_sorted[df_sorted['date'] > latest_date].copy()
    
    # If we have future data, handle it
    if not future_df.empty:
        # We have future predictions
        
        # Add the main historical predicted price line (including the last point)
        if not historical_df.empty:
            fig.add_trace(
                go.Scatter(
                    x=historical_df['date'],
                    y=historical_df['predicted_price'],
                    mode='lines',
                    name='Historical Predictions',
                    line=dict(color='red', width=2)
                )
            )
            
            # Highlight the last historical prediction with a special color
            fig.add_trace(
                go.Scatter(
                    x=[historical_df['date'].iloc[-1]],
                    y=[historical_df['predicted_price'].iloc[-1]],
                    mode='markers',
                    name='Last Historical Prediction',
                    marker=dict(
                        color='purple',
                        size=10,
                        line=dict(width=2, color='black')
                    )
                )
            )
        
        # Add future predictions with a different color but connect to the last historical
        all_predictions = pd.concat([historical_df.iloc[-1:], future_df])
        
        fig.add_trace(
            go.Scatter(
                x=all_predictions['date'],
                y=all_predictions['predicted_price'],
                mode='lines+markers',
                name='Future Predictions',
                line=dict(color='darkred', width=2),
                marker=dict(
                    color='darkred',
                    size=10,
                    line=dict(width=2, color='black')
                )
            )
        )
    else:
        # No future predictions, just historical data
        
        # If we have at least 2 data points, connect all predictions with a line
        if len(historical_df) > 1:
            # Add the complete prediction line
            fig.add_trace(
                go.Scatter(
                    x=historical_df['date'],
                    y=historical_df['predicted_price'],
                    mode='lines',
                    name='Historical Predictions',
                    line=dict(color='red', width=2)
                )
            )
            
            # Add yellow line segment between previous prediction and latest prediction
            if len(historical_df) > 1:
                fig.add_trace(
                    go.Scatter(
                        x=[historical_df['date'].iloc[-2], historical_df['date'].iloc[-1]],
                        y=[historical_df['predicted_price'].iloc[-2], historical_df['predicted_price'].iloc[-1]],
                        mode='lines',
                        name='Latest Prediction',
                        line=dict(color='yellow', width=4)
                    )
                )
        else:
            # If we only have one data point
            fig.add_trace(
                go.Scatter(
                    x=historical_df['date'],
                    y=historical_df['predicted_price'],
                    mode='markers',
                    name='Latest Prediction',
                    marker=dict(color='darkred', size=12)
                )
            )
    
    # Calculate and add rolling average of actual price
    if len(df) >= window_size:
        # Use the same df without the last point for the rolling average
        actual_display_df['rolling_avg'] = actual_display_df['actual_price'].rolling(window=window_size).mean()
        fig.add_trace(
            go.Scatter(
                x=actual_display_df['date'],
                y=actual_display_df['rolling_avg'],
                mode='lines',
                name=f'{window_size}-Day Rolling Avg',
                line=dict(color='green', width=1.5, dash='dash')
            )
        )
    
    # Update layout
    fig.update_layout(
        title=f"{stock_symbol} - Actual vs. Predicted Price",
        xaxis_title="Date",
        yaxis_title="Price",
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
        height=600
    )
    
    return fig

def plot_error_analysis(df, stock_symbol):
    """
    Create a visualization of prediction errors over time
    
    Args:
        df: DataFrame with date, predicted_price, and actual_price columns
        stock_symbol: Stock ticker symbol
    """
    # Calculate errors
    df = df.copy()
    df['error'] = df['actual_price'] - df['predicted_price']
    df['abs_error'] = abs(df['error'])
    df['pct_error'] = (df['error'] / df['actual_price']) * 100
    
    # Create subplot figure
    fig = make_subplots(
        rows=3, cols=1,
        shared_xaxes=True,
        vertical_spacing=0.1,
        subplot_titles=(
            "Raw Prediction Error Over Time (Actual - Predicted)",
            "Absolute Error Over Time",
            "Percentage Error Over Time (%)"
        ),
        row_heights=[0.33, 0.33, 0.33]
    )
    
    # Add error trace
    fig.add_trace(
        go.Scatter(
            x=df['date'],
            y=df['error'],
            mode='lines',
            name='Error',
            line=dict(color='purple')
        ),
        row=1, col=1
    )
    
    # Add zero line
    fig.add_trace(
        go.Scatter(
            x=df['date'],
            y=[0] * len(df),
            mode='lines',
            name='Zero Error',
            line=dict(color='black', dash='dash', width=1)
        ),
        row=1, col=1
    )
    
    # Add absolute error trace
    fig.add_trace(
        go.Scatter(
            x=df['date'],
            y=df['abs_error'],
            mode='lines',
            name='Absolute Error',
            line=dict(color='orange'),
            fill='tozeroy'
        ),
        row=2, col=1
    )
    
    # Add percentage error trace
    fig.add_trace(
        go.Scatter(
            x=df['date'],
            y=df['pct_error'],
            mode='lines',
            name='Percentage Error',
            line=dict(color='green'),
            fill='tozeroy'
        ),
        row=3, col=1
    )
    
    # Calculate y-axis ranges with padding
    error_max = max(abs(df['error'].max()), abs(df['error'].min())) * 1.1
    abs_error_max = df['abs_error'].max() * 1.1
    pct_error_max = df['pct_error'].max() * 1.1
    
    # Set y-axis ranges
    fig.update_yaxes(range=[-error_max, error_max], title_text="Price Units", row=1, col=1)
    fig.update_yaxes(range=[0, abs_error_max], title_text="Price Units", row=2, col=1)
    fig.update_yaxes(range=[0, pct_error_max], title_text="Percent (%)", row=3, col=1)
    
    # Update layout
    fig.update_layout(
        title=f"{stock_symbol} - Prediction Error Analysis",
        height=900,
        showlegend=False,
        xaxis3_title="Date"
    )
    
    # Add mean error lines and annotations
    mean_error = df['error'].mean()
    mean_abs_error = df['abs_error'].mean()
    mean_pct_error = df['pct_error'].mean()
    
    # Add mean lines
    fig.add_shape(type="line", x0=df['date'].min(), x1=df['date'].max(), 
                 y0=mean_error, y1=mean_error, line=dict(color="red", width=1, dash="dot"),
                 row=1, col=1)
    fig.add_annotation(x=df['date'].max(), y=mean_error, text=f"Mean: {mean_error:.2f}", 
                      showarrow=False, xanchor="right", row=1, col=1)
    
    fig.add_shape(type="line", x0=df['date'].min(), x1=df['date'].max(), 
                 y0=mean_abs_error, y1=mean_abs_error, line=dict(color="red", width=1, dash="dot"),
                 row=2, col=1)
    fig.add_annotation(x=df['date'].max(), y=mean_abs_error, text=f"Mean: {mean_abs_error:.2f}", 
                      showarrow=False, xanchor="right", row=2, col=1)
    
    fig.add_shape(type="line", x0=df['date'].min(), x1=df['date'].max(), 
                 y0=mean_pct_error, y1=mean_pct_error, line=dict(color="red", width=1, dash="dot"),
                 row=3, col=1)
    fig.add_annotation(x=df['date'].max(), y=mean_pct_error, text=f"Mean: {mean_pct_error:.2f}%", 
                      showarrow=False, xanchor="right", row=3, col=1)
    
    return fig

def plot_error_distribution(df, stock_symbol):
    """
    Create a visualization of the error distribution
    
    Args:
        df: DataFrame with date, predicted_price, and actual_price columns
        stock_symbol: Stock ticker symbol
    """
    # Calculate errors
    df = df.copy()
    df['error'] = df['actual_price'] - df['predicted_price']
    df['pct_error'] = (df['error'] / df['actual_price']) * 100
    
    # Create subplot figure
    fig = make_subplots(
        rows=1, cols=2,
        subplot_titles=(
            "Error Distribution",
            "Percentage Error Distribution"
        ),
        column_widths=[0.5, 0.5]
    )
    
    # Add error histogram
    fig.add_trace(
        go.Histogram(
            x=df['error'],
            name='Error',
            marker_color='purple',
            opacity=0.7,
            nbinsx=30
        ),
        row=1, col=1
    )
    
    # Add percentage error histogram
    fig.add_trace(
        go.Histogram(
            x=df['pct_error'],
            name='Percentage Error',
            marker_color='green',
            opacity=0.7,
            nbinsx=30
        ),
        row=1, col=2
    )
    
    # Add vertical lines at zero
    fig.add_vline(x=0, line_dash="dash", line_color="black", row=1, col=1)
    fig.add_vline(x=0, line_dash="dash", line_color="black", row=1, col=2)
    
    # Update layout
    fig.update_layout(
        title=f"{stock_symbol} - Error Distribution Analysis",
        height=500,
        showlegend=False
    )
    
    return fig

def calculate_metrics(df):
    """Calculate prediction performance metrics"""
    # Basic error metrics
    rmse = np.sqrt(mean_squared_error(df['actual_price'], df['predicted_price']))
    mae = mean_absolute_error(df['actual_price'], df['predicted_price'])
    r2 = r2_score(df['actual_price'], df['predicted_price'])
    
    # Mean absolute percentage error
    mape = np.mean(np.abs((df['actual_price'] - df['predicted_price']) / df['actual_price'])) * 100
    
    # Directional accuracy (correctly predicting up/down movements)
    df['actual_direction'] = df['actual_price'].diff().apply(lambda x: 1 if x >= 0 else 0)
    df['predicted_direction'] = df['predicted_price'].diff().apply(lambda x: 1 if x >= 0 else 0)
    direction_match = (df['actual_direction'] == df['predicted_direction']).sum()
    direction_accuracy = direction_match / (len(df) - 1) * 100  # -1 because diff loses one row
    
    return {
        'RMSE': rmse,
        'MAE': mae,
        'R²': r2,
        'MAPE': mape,
        'Direction Accuracy': direction_accuracy
    }

def plot_accuracy_vs_horizon(df, stock_symbol, max_days=10):
    """
    Analyze how prediction accuracy changes with prediction horizon
    
    Args:
        df: DataFrame with date, predicted_price, and actual_price columns
        stock_symbol: Stock ticker symbol
        max_days: Maximum prediction horizon to analyze
    """
    # Initialize containers for metrics
    horizons = list(range(1, max_days+1))
    rmse_values = []
    mae_values = []
    mape_values = []
    dir_acc_values = []
    
    # Calculate metrics for each horizon
    for horizon in horizons:
        # Create shifted predictions (as if they were made n days in advance)
        df_shifted = df.copy()
        df_shifted['predicted_price'] = df_shifted['predicted_price'].shift(-horizon)
        df_shifted = df_shifted.dropna()
        
        if len(df_shifted) > 0:
            # Calculate metrics
            metrics = calculate_metrics(df_shifted)
            rmse_values.append(metrics['RMSE'])
            mae_values.append(metrics['MAE'])
            mape_values.append(metrics['MAPE'])
            dir_acc_values.append(metrics['Direction Accuracy'])
        else:
            # Not enough data for this horizon
            rmse_values.append(np.nan)
            mae_values.append(np.nan)
            mape_values.append(np.nan)
            dir_acc_values.append(np.nan)
    
    # Create subplot figure
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=(
            "RMSE vs Prediction Horizon",
            "MAE vs Prediction Horizon",
            "MAPE vs Prediction Horizon",
            "Direction Accuracy vs Prediction Horizon"
        )
    )
    
    # Add traces
    fig.add_trace(
        go.Scatter(
            x=horizons,
            y=rmse_values,
            mode='lines+markers',
            name='RMSE',
            line=dict(color='red')
        ),
        row=1, col=1
    )
    
    fig.add_trace(
        go.Scatter(
            x=horizons,
            y=mae_values,
            mode='lines+markers',
            name='MAE',
            line=dict(color='blue')
        ),
        row=1, col=2
    )
    
    fig.add_trace(
        go.Scatter(
            x=horizons,
            y=mape_values,
            mode='lines+markers',
            name='MAPE',
            line=dict(color='green')
        ),
        row=2, col=1
    )
    
    fig.add_trace(
        go.Scatter(
            x=horizons,
            y=dir_acc_values,
            mode='lines+markers',
            name='Direction Accuracy',
            line=dict(color='purple')
        ),
        row=2, col=2
    )
    
    # Update layout
    fig.update_layout(
        title=f"{stock_symbol} - Prediction Accuracy vs Horizon",
        height=800,
        showlegend=False
    )
    
    return fig

def plot_performance_by_volatility(df, stock_symbol, window=20):
    """
    Analyze how prediction accuracy relates to market volatility
    
    Args:
        df: DataFrame with date, predicted_price, and actual_price columns
        stock_symbol: Stock ticker symbol
        window: Rolling window size for volatility calculation
    """
    # Calculate volatility
    df = df.copy()
    df['volatility'] = df['actual_price'].pct_change().rolling(window=window).std() * np.sqrt(252)  # Annualized
    
    # Calculate absolute percentage error
    df['pct_error'] = abs((df['actual_price'] - df['predicted_price']) / df['actual_price']) * 100
    
    # Remove NaN values
    df = df.dropna()
    
    # Check if we have enough data after preprocessing
    if len(df) < 2:
        # Create an empty figure with a message
        fig = go.Figure()
        fig.add_annotation(
            x=0.5, y=0.5,
            text="Not enough data points to analyze volatility relationship",
            showarrow=False,
            font=dict(size=16)
        )
        fig.update_layout(
            title=f"{stock_symbol} - Prediction Error vs Volatility (Insufficient Data)",
            xaxis_title="Volatility (Annualized)",
            yaxis_title="Percentage Error (%)",
            height=600
        )
        return fig
    
    # Create scatter plot
    fig = go.Figure()
    
    # Convert dates to numerical values for colorscale
    # First ensure date column is datetime
    if not pd.api.types.is_datetime64_any_dtype(df['date']):
        df['date'] = pd.to_datetime(df['date'])
    
    # Create numerical representation of dates for the colorscale
    # This converts the dates to integers (days since epoch)
    date_nums = (df['date'] - df['date'].min()).dt.total_seconds() / (24 * 60 * 60)
    
    fig.add_trace(
        go.Scatter(
            x=df['volatility'],
            y=df['pct_error'],
            mode='markers',
            marker=dict(
                size=8,
                color=date_nums,  # Use numerical date representation
                colorscale='Viridis',
                showscale=True,
                colorbar=dict(
                    title="Date",
                    thickness=15,  # Make it thinner
                    yanchor="top",
                    y=1,
                    xanchor="left",
                    x=1.05,        # Position it to the right of the plot
                    outlinewidth=0
                )
            ),
            text=df['date'].dt.strftime('%Y-%m-%d'),  # Format dates as strings for hover
            hovertemplate='Date: %{text}<br>Volatility: %{x:.4f}<br>Prediction Error: %{y:.2f}%'
        )
    )
    
    # Calculate correlation
    correlation = df['volatility'].corr(df['pct_error'])
    
    # Add trend line
    z = np.polyfit(df['volatility'], df['pct_error'], 1)
    p = np.poly1d(z)
    fig.add_trace(
        go.Scatter(
            x=df['volatility'],
            y=p(df['volatility']),
            mode='lines',
            name='Trend',
            line=dict(color='red', dash='dash')
        )
    )
    
    # Set y-axis range with some padding
    max_error = df['pct_error'].max() * 1.1
    
    # Update layout
    fig.update_layout(
        title=f"{stock_symbol} - Prediction Error vs Volatility (Correlation: {correlation:.4f})",
        xaxis_title="Volatility (Annualized)",
        yaxis_title="Percentage Error (%)",
        height=600,
        yaxis=dict(range=[0, max_error]),
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        ),
        margin=dict(r=150)  # Increase right margin for colorbar
    )
    
    return fig

def sample_predictions_to_csv(df, output_path):
    """Save predictions to CSV for further analysis"""
    df.to_csv(output_path, index=False)
    print(f"Saved predictions to {output_path}")

def load_feature_importance():
    """
    Load feature importance data for Random Forest and LightGBM models
    
    Returns:
        Tuple of DataFrames containing feature importance for RF and LightGBM
    """
    try:
        conn = get_db_connection()
        
        # Query for Random Forest feature importance
        rf_query = """
        SELECT feature, importance
        FROM model_feature_importance
        WHERE model_name = 'random_forest'
        ORDER BY importance DESC
        """
        
        # Query for LightGBM feature importance
        lgbm_query = """
        SELECT feature, importance
        FROM model_feature_importance
        WHERE model_name = 'lightgbm'
        ORDER BY importance DESC
        """
        
        rf_importance = pd.read_sql(rf_query, conn)
        lgbm_importance = pd.read_sql(lgbm_query, conn)
        
        conn.close()
        
        return rf_importance, lgbm_importance
    
    except Exception as e:
        print(f"Error loading feature importance data: {e}")
        return pd.DataFrame(), pd.DataFrame()

def load_model_evaluations():
    """
    Load model evaluation data from the database
    
    Returns:
        DataFrame containing model evaluation metrics
    """
    try:
        # Connect to database
        conn = get_db_connection()
        
        # Query to get model evaluations
        query = """
        SELECT * FROM model_evaluations
        ORDER BY training_date DESC
        """
        
        # Load data
        df = pd.read_sql_query(query, conn, params=[])
        conn.close()
        
        if not df.empty:
            print(f"Successfully loaded {len(df)} model evaluations from database")
            return df
        else:
            print("No model evaluation data found in database")
            return pd.DataFrame()
            
    except Exception as e:
        print(f"Error loading model evaluation data: {e}")
        return pd.DataFrame()

def plot_model_comparison(df):
    """
    Create a visualization comparing model performance across different stocks
    
    Args:
        df: DataFrame containing model evaluation data
    """
    if df.empty:
        return None
        
    # Prepare data for visualization
    # Extract model name and stock symbol from model path if available
    if 'model_path' in df.columns:
        try:
            # Extract stock symbol from model path (assumed format: models/SYMBOL_model.pkl)
            df['stock_symbol'] = df['model_path'].str.extract(r'models/([A-Z]+)_model\.pkl')
        except:
            # If extraction fails, try to use existing stock_symbol column if it exists
            if 'stock_symbol' not in df.columns:
                df['stock_symbol'] = 'Unknown'
    
    # Select metrics to visualize
    error_metrics = []
    if 'rmse' in df.columns:
        error_metrics.append('rmse')
    if 'mae' in df.columns:
        error_metrics.append('mae')
        
    accuracy_metrics = []
    if 'r2' in df.columns:
        accuracy_metrics.append('r2')
    
    all_metrics = error_metrics + accuracy_metrics
    if not all_metrics:
        return None
    
    # Create a figure with sufficient subplots for all metrics
    fig = make_subplots(
        rows=len(all_metrics), 
        cols=1,
        subplot_titles=[f"{metric.upper()} by Stock" for metric in all_metrics],
        vertical_spacing=0.1
    )
    
    # Process each group of metrics
    row_idx = 1
    
    # First add error metrics (lower is better)
    for metric in error_metrics:
        # Sort by metric (ascending for error metrics)
        sorted_df = df.sort_values(metric, ascending=True)
        
        # Get values
        symbols = sorted_df['stock_symbol'].values
        values = sorted_df[metric].values
        
        # Add bar chart
        fig.add_trace(
            go.Bar(
                x=symbols,
                y=values,
                name=metric.upper(),
                marker_color='red',
                text=[f"{v:.4f}" for v in values],
                textposition='auto'
            ),
            row=row_idx, col=1
        )
        
        # Add a horizontal line for the average
        avg_value = np.mean(values)
        fig.add_shape(
            type='line',
            x0=-0.5,
            x1=len(symbols) - 0.5,
            y0=avg_value,
            y1=avg_value,
            line=dict(color='black', dash='dash'),
            row=row_idx, col=1
        )
        
        # Add text for average
        fig.add_annotation(
            x=len(symbols) - 1,
            y=avg_value,
            text=f"Avg: {avg_value:.4f}",
            showarrow=False,
            row=row_idx, col=1
        )
        
        # Add explicit label to indicate that lower is better
        fig.add_annotation(
            x=0,
            y=max(values) * 0.95,
            text="Lower is better",
            showarrow=False,
            xanchor="left",
            font=dict(color="red", size=12),
            row=row_idx, col=1
        )
        
        # Update y-axis label
        fig.update_yaxes(title_text=f"{metric.upper()} (Error)", row=row_idx, col=1)
        
        row_idx += 1
    
    # Then add accuracy metrics (higher is better)
    for metric in accuracy_metrics:
        # Sort by metric (descending for accuracy metrics)
        sorted_df = df.sort_values(metric, ascending=False)
        
        # Get values
        symbols = sorted_df['stock_symbol'].values
        values = sorted_df[metric].values
        
        # Add bar chart
        fig.add_trace(
            go.Bar(
                x=symbols,
                y=values,
                name=metric.upper(),
                marker_color='blue',
                text=[f"{v:.4f}" for v in values],
                textposition='auto'
            ),
            row=row_idx, col=1
        )
        
        # Add a horizontal line for the average
        avg_value = np.mean(values)
        fig.add_shape(
            type='line',
            x0=-0.5,
            x1=len(symbols) - 0.5,
            y0=avg_value,
            y1=avg_value,
            line=dict(color='black', dash='dash'),
            row=row_idx, col=1
        )
        
        # Add text for average
        fig.add_annotation(
            x=len(symbols) - 1,
            y=avg_value,
            text=f"Avg: {avg_value:.4f}",
            showarrow=False,
            row=row_idx, col=1
        )
        
        # Add explicit label to indicate that higher is better
        fig.add_annotation(
            x=0,
            y=max(values) * 0.95,
            text="Higher is better",
            showarrow=False,
            xanchor="left",
            font=dict(color="blue", size=12),
            row=row_idx, col=1
        )
        
        # Update y-axis label
        fig.update_yaxes(title_text=f"{metric.upper()} (Accuracy)", row=row_idx, col=1)
        
        row_idx += 1
    
    # Update x-axis label for the last plot
    fig.update_xaxes(title_text="Stock Symbol", row=len(all_metrics), col=1)
    
    # Update layout
    fig.update_layout(
        title="Model Performance Comparison by Stock",
        height=300 * len(all_metrics),
        showlegend=False
    )
    
    return fig

def plot_performance_over_time(df):
    """
    Create a visualization showing model performance over time
    
    Args:
        df: DataFrame containing model evaluation data with training_date column
    """
    if df.empty or 'training_date' not in df.columns:
        return None
    
    # Convert training_date to datetime if not already
    if not pd.api.types.is_datetime64_any_dtype(df['training_date']):
        df['training_date'] = pd.to_datetime(df['training_date'])
    
    # Sort by training date
    df = df.sort_values('training_date')
    
    # Select metrics to visualize
    metrics = []
    if 'rmse' in df.columns:
        metrics.append('rmse')
    if 'mae' in df.columns:
        metrics.append('mae')
    if 'r2' in df.columns:
        metrics.append('r2')
    
    if not metrics:
        return None
    
    # Extract stock symbol from model path if available
    if 'model_path' in df.columns and 'stock_symbol' not in df.columns:
        try:
            df['stock_symbol'] = df['model_path'].str.extract(r'models/([A-Z]+)_model\.pkl')
        except:
            df['stock_symbol'] = 'Unknown'
    
    # Create figure
    fig = go.Figure()
    
    # Get unique stocks
    stocks = df['stock_symbol'].unique() if 'stock_symbol' in df.columns else ['Unknown']
    
    # Create a color map for stocks
    colors = px.colors.qualitative.Plotly[:len(stocks)]
    color_map = {stock: color for stock, color in zip(stocks, colors)}
    
    # Add traces for each metric and stock
    for metric in metrics:
        dash_style = 'dash' if metric in ['rmse', 'mae'] else 'solid'
        line_width = 2 if metric == 'r2' else 1.5
        
        for stock in stocks:
            # Filter for this stock
            stock_df = df[df['stock_symbol'] == stock] if 'stock_symbol' in df.columns else df
            
            # Set color based on stock
            color = color_map.get(stock, 'blue')
            
            # Add trace with improved styling
            fig.add_trace(
                go.Scatter(
                    x=stock_df['training_date'],
                    y=stock_df[metric],
                    mode='lines+markers',
                    name=f"{stock} - {metric.upper()}",
                    legendgroup=stock,  # Group by stock in legend
                    marker=dict(size=6),
                    line=dict(
                        color=color,
                        dash=dash_style,
                        width=line_width
                    )
                )
            )
    
    # Update layout
    fig.update_layout(
        title={
            "text": "Model Performance Trends Over Time",
            "y": 0.95,  # Move title up to make more space
            "x": 0.5,
            "xanchor": "center",
            "yanchor": "top"
        },
        xaxis_title="Training Date",
        yaxis_title="Metric Value",
        height=750,  # Increase height for better spacing
        margin=dict(t=180, r=20, l=20, b=50),  # Add more margin all around
        legend=dict(
            orientation="h",  
            yanchor="bottom",
            y=1.05,  # Position legend higher above the plot
            xanchor="center",  # Center the legend
            x=0.5,
            font=dict(size=10),  # Smaller font for legend text
            itemsizing="constant",  # Make legend items same size
            tracegroupgap=10  # Add gap between legend groups
        ),
        # Add annotations to explain chart elements
        annotations=[
            dict(
                x=0.01,
                y=1.03,
                xref="paper",
                yref="paper",
                text="<b>Chart Guide:</b> Solid lines = R² (higher is better), Dashed lines = RMSE/MAE (lower is better)",
                showarrow=False,
                font=dict(size=11),
                align="left"
            )
        ]
    )
    
    return fig

if __name__ == "__main__":
    # Example usage
    stock_symbol = 'AAPL'
    start_date = '2023-01-01'
    end_date = datetime.now().strftime('%Y-%m-%d')
    
    # For testing without database, create dummy prediction data
    # In real use, you would use load_predictions(stock_symbol, start_date, end_date)
    
    # Create date range
    dates = pd.date_range(start=start_date, end=end_date)
    
    # Create dummy data
    np.random.seed(42)  # For reproducibility
    actual_prices = np.linspace(150, 200, len(dates)) + np.random.normal(0, 5, len(dates))
    predicted_prices = actual_prices + np.random.normal(0, 10, len(dates))
    
    # Create DataFrame
    df = pd.DataFrame({
        'date': dates,
        'stock_symbol': stock_symbol,
        'actual_price': actual_prices,
        'predicted_price': predicted_prices
    })
    
    # Calculate metrics
    metrics = calculate_metrics(df)
    print("\nPrediction Performance Metrics:")
    for name, value in metrics.items():
        print(f"{name}: {value:.4f}")
    
    # Create output directory if it doesn't exist
    os.makedirs("visualizations/static", exist_ok=True)
    
    # Create visualizations
    comparison_fig = plot_prediction_comparison(df, stock_symbol)
    comparison_fig.write_html(f"visualizations/static/{stock_symbol}_prediction_comparison.html")
    
    error_fig = plot_error_analysis(df, stock_symbol)
    error_fig.write_html(f"visualizations/static/{stock_symbol}_error_analysis.html")
    
    distribution_fig = plot_error_distribution(df, stock_symbol)
    distribution_fig.write_html(f"visualizations/static/{stock_symbol}_error_distribution.html")
    
    horizon_fig = plot_accuracy_vs_horizon(df, stock_symbol)
    horizon_fig.write_html(f"visualizations/static/{stock_symbol}_accuracy_horizon.html")
    
    volatility_fig = plot_performance_by_volatility(df, stock_symbol)
    volatility_fig.write_html(f"visualizations/static/{stock_symbol}_volatility_analysis.html")
    
    # Save sample predictions to CSV
    os.makedirs("data", exist_ok=True)
    sample_predictions_to_csv(df.head(100), "data/sample_predictions.csv")
    
    print("All visualizations created successfully!") 